{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to read data from input transcript file for all seasons\n",
    "#Extracted data will be stored into a file ../dataset/friends_dataset_allseasons_tmp.csv\n",
    "import re\n",
    "import sys \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#key words to skip\n",
    "keywords=['End','Closing Credits','1017-1018 - The Last One','OPENING CREDITS','COMMERCIAL BREAK','THE END','Opening Credits','Commercial break','END','Credits','OPENING TITLES','CLOSING CREDITS']\n",
    "keywordstr = '^\\s*(END|Closing Credits|OPENING CREDITS|COMMERCIAL(\\s+BREAK)?|CLOSING TITLES|THE END|OPENING TITLES|Commercial|Credits|HTMLed by|To Be Continued\\.*|The Next Morning)\\s*$'\n",
    "# Creating an empty Dataframe with column names only\n",
    "df = pd.DataFrame(columns=['Season', 'Episode', 'Episode Name','Location','Character','Dialogue'])\n",
    "\n",
    "\n",
    "#Reading all transcript files from given path\n",
    "\n",
    "def readfiles(dirpath):\n",
    "    dff = pd.DataFrame(columns=['File', 'Season', 'Episode'])\n",
    "    for file in os.listdir(dirpath):\n",
    "        if file.endswith(\".csv\"):\n",
    "            fileName=os.path.join(dirpath, file)\n",
    "            if re.search(\"^\\d{3}\\.\",file):\n",
    "                mo = re.search(\"^(\\d)(\\d\\d)\\.\",file)\n",
    "                season = mo.group(1)\n",
    "                episode = mo.group(2)\n",
    "            elif re.search(\"^\\d{4}\\.\",file):\n",
    "                mo = re.search(\"^(\\d\\d)(\\d\\d)\\.\",file)\n",
    "                season = mo.group(1)\n",
    "                episode = mo.group(2)\n",
    "            elif re.search(\"^\\d{3}-\\d{3}\\.\",file):\n",
    "                mo = re.search(\"^(\\d)(\\d\\d)-\\d(\\d\\d)\\.\",file)\n",
    "                season = mo.group(1)\n",
    "                episode = mo.group(2) + \"-\" + mo.group(3)            \n",
    "            elif re.search(\"^\\d{4}-\\d{4}\\.\",file):\n",
    "                mo = re.search(\"^(\\d\\d)(\\d\\d)-\\d\\d(\\d\\d)\\.\",file)\n",
    "                season = mo.group(1)\n",
    "                episode = mo.group(2) + \"-\" + mo.group(3)\n",
    "            else:\n",
    "                print(\"Error - File name is not in correct format: \", filename)\n",
    "            dff = dff.append({'File': fileName,'Season':season, 'Episode':episode}, ignore_index=True)\n",
    "            #print (\"File: {}.Season: {}, Episode: {}\".format(fileName,season,episode))\n",
    "    dff[\"Season\"] = dff['Season'].astype('int')\n",
    "    dff=dff.sort_values(['Season', 'Episode'], ascending=[True, True])\n",
    "    return dff\n",
    "\n",
    "dfn = readfiles('../transcripts/allseasons')\n",
    "#print (dfn)\n",
    "\n",
    "# iterate through each row and select  \n",
    "for index, row in dfn.iterrows(): \n",
    "    print (row[\"File\"], row[\"Season\"],row['Episode'])\n",
    "    fileName=row[\"File\"]\n",
    "    season=row[\"Season\"]\n",
    "    episode=row['Episode']\n",
    "\n",
    "    #open input transcript file\n",
    "    #mbcs\n",
    "    with open(fileName,encoding=\"utf-8\") as tsf: \n",
    "    #with open(fileName) as tsf: \n",
    "        #Lines = tsf.readlines()\n",
    "        data = tsf.read()\n",
    "        #print (data)\n",
    "        #(?<!^) --> Not starting with string\n",
    "        #print (\"--------------------------------------------------------------------------------------\")\n",
    "        data_new = re.sub(\"([^\\n])((\\[|\\()\\s*(Flashback |Tag )?scene(:|;|,| ))\",r\"\\1\\n\\2\",data,flags=re.I)\n",
    "        #print (data_new)\n",
    "        Lines = list(data_new.split(\"\\n\")) \n",
    "        episodeName=\"\"\n",
    "        episodeFlag = 1\n",
    "        sceneName = \"\"\n",
    "        locationName = \"\"\n",
    "        for linedata in Lines:\n",
    "            characterName = \"\"\n",
    "            dialogue = \"\"\n",
    "            #print (\"--{}--\".format(line))\n",
    "            line = linedata.strip('\\r?\\n')\n",
    "            if re.match(\"^\\s*$\",line):\n",
    "                continue\n",
    "            if episodeFlag == 1 and not re.search(\"^\\s*(\\[|\\()\\s*(Flashback |Tag )?scene(:|;|,| )\",line,re.IGNORECASE):\n",
    "                episodeName = re.sub(r\"^\\s+|\\s+$\",\"\",line,flags=re.I)\n",
    "                episodeFlag=0\n",
    "                #print (\"Season: {} and Episode: {}\".format(season,episodeName))\n",
    "                continue\n",
    "            \n",
    "            if not re.match(\"^\\s*(Dutch Phrases by|Produced by|Flashback clips transcribed by|With Minot Adjustments by|Transcript by|Episodes Orginally Transcribed by|With Help From|Episodes Ori?ginally Transcribed by|With Scenes Taken From Episodes Transcribed by|TIME LAPSE|Aired|Directed by|Ending Credits|Parts? |Commerical Break\\.?|Story by|Teleplay by|Minor additions and adjustments by|Contrl\\d+\\.gif|Originally written|Tran?scribed by|Written by|Additional transcribing by|With Minor Adjustments by|\\(Note: The previously unseen).*$\", line,re.IGNORECASE):\n",
    "                if re.search(\"^\\s*(\\[|\\()\\s*(Russian to Roman alphabet|Flashback |Tag )?scene(:|;|,| )\",line,re.IGNORECASE):\n",
    "                    mo = re.search(\"^\\s*(\\[|\\()\\s*(Flashback |Tag )?scene(:|;|,| )(.+?)$\",line,re.IGNORECASE)\n",
    "                    sceneData = mo.group(4)\n",
    "                    if re.search(\"continued from earlier\",sceneData,re.IGNORECASE):\n",
    "                        continue\n",
    "                    elif not re.match(\"^\\s*$\",sceneData):\n",
    "                        smo = re.search(\"^(....+?)([,;:\\.\\-\\]]|$)\",sceneData,re.IGNORECASE)\n",
    "                        \n",
    "                        #print (\"Scene Data: \", sceneData )\n",
    "                        try:\n",
    "                            locationName = re.sub(r\"^\\s+|\\s+$\",\"\",smo.group(1),flags=re.I).lower()                            \n",
    "                        except:\n",
    "                            print(\"Something went wrong when extracting Scene Details: \", sceneData)\n",
    "                            sys.exit()\n",
    "                          \n",
    "                        if re.match(\"^\\s*$\",locationName):\n",
    "                            print (\"Error ... Location Name is not available\",sceneData)\n",
    "                            sys.exit()\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        print (\"Error ... Scene Details is not available\")\n",
    "                        sys.exit()\n",
    "                elif re.search(\"^\\s*(\\*|<|\\[|\\(|\\{)\",line,re.IGNORECASE):\n",
    "                    continue\n",
    "                elif re.match(\"^\\s*Commercial Break\\s*$\",line):\n",
    "                    continue\n",
    "                elif re.search(\"^([^:]+)\\s*:\",line,re.IGNORECASE):\n",
    "                    dmo = re.search(\"^([^:]+)\\s*:\\s*(.*)$\",line,re.IGNORECASE)\n",
    "                    characterName_tmp1 = re.sub(r'\\(.+?\\)',\"\",dmo.group(1),flags=re.I)\n",
    "                    characterName_tmp = re.sub(r'\\[.+?\\]',\"\",characterName_tmp1,flags=re.I)\n",
    "                    characterName = re.sub(r\"^\\s+|\\s+$\",\"\",characterName_tmp,flags=re.I)\n",
    "\n",
    "                    \n",
    "                    #dialogue_tmp = re.sub(\"(\\(|\\[).+?\\1\",\"\",dmo.group(2),flags=re.I)\n",
    "                    \n",
    "                    dialogue = re.sub(\"^\\s+|\\s+$\",\"\",dmo.group(2),flags=re.I)\n",
    "                    \n",
    "                    \n",
    "                    if re.search(\"(\\[|\\()\\s*(Flashback |Tag )?scene(:|;|,| )\",line,re.IGNORECASE):\n",
    "                        print (\"Error Need to clean up data which are having 'secen:' text in middile dialogue content: -->\",line)\n",
    "                        sys.exit()\n",
    "                    if re.match(\"^\\s*$\",characterName):\n",
    "                        print (\"Error ...There is no Character Name: \", line)\n",
    "                        sys.exit()\n",
    "                    if re.match(\"^\\s*$\",dialogue):\n",
    "                        print (\"Error ...There is no dialogue content: \", line)\n",
    "                        sys.exit()                  \n",
    "                    #print (dmo.groups())\n",
    "#                elif line in keywords:\n",
    "                elif re.search(keywordstr,line,re.IGNORECASE):\n",
    "                    continue\n",
    "                else:\n",
    "                    print (\"Warning ...... line is not in proper format: \", season, episode,line)\n",
    "                    #sys.exit()\n",
    "                    continue\n",
    "                #print(season,episode,episodeName,locationName,characterName,dialogue)\n",
    "                df = df.append({'Season':season, 'Episode':episode, 'Episode Name':episodeName,'Location':locationName,'Character':characterName,'Dialogue':dialogue}, ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "    #reak\n",
    "\n",
    "#print (df)\n",
    "df.to_csv('../dataset/friends_dataset_allseasons_tmp.csv',sep='\\t',index=False)\n",
    "                \n",
    "                \n",
    "                                                                                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Reading data from ../dataset/friends_dataset_allseasons_tmp.csv and cleaning up 'Character' and 'Location' columns\n",
    "#Finally cleaned data will be stored in ../dataset/friends_dataset_allseasons.csv\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "df = pd.read_csv('../dataset/friends_dataset_allseasons_tmp.csv',sep='\\t')\n",
    "print(list(df.columns.values))\n",
    "#print (df.head(5))\n",
    "\n",
    "# Get the unique characters and their corresponding dialogue count\n",
    "#print (df['Character'].value_counts().head(20) )\n",
    "\n",
    "\"\"\"\n",
    "#cleaning up (RACHEL|RACH|RAHCEL|Racel|Rache|Rache) in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Ra[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "#df_temp = df[df['Character'].str.contains('^Ra', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "df['Character'] = df['Character'].replace('^\\s*(RACHEL|RACH|RAHCEL|Racel|Rache|Rache)\\s*$', 'Rachel', regex=True)\n",
    "\n",
    "\n",
    "#cleaning up (ROSS|ross|Ross) in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Ro[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "#df_temp = df[df['Character'].str.contains('^Ro', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "df['Character'] = df['Character'].replace('^\\s*(ROSS|ross|Ross)\\s*$', 'Ross', regex=True)\n",
    "\n",
    "\n",
    "#cleaning up (Joey|JOEY|joey) in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Jo[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "#df_temp = df[df['Character'].str.contains('^Jo', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "df['Character'] = df['Character'].replace('^\\s*(Joey|JOEY|joey)\\s*$', 'Joey', regex=True)\n",
    "\n",
    "\n",
    "#cleaning up (Monica|MONICA|monica) in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Mo[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "#df_temp = df[df['Character'].str.contains('^Mo', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "df['Character'] = df['Character'].replace('^\\s*(Monica|MONICA|monica|MNCA)\\s*$', 'Monica', regex=True)\n",
    "\n",
    "#cleaning up (Phoebe|PHOEBE|Phoehe|PHOE) in 'Character' column\n",
    "#df_temp = df[df['Character'].str.contains('^Ph[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "df_temp = df[df['Character'].str.contains('^Ph', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "df['Character'] = df['Character'].replace('^\\s*(Phoebe|PHOEBE|Phoehe|PHOE)\\s*$', 'Phoebe', regex=True)\n",
    "\n",
    "\n",
    "#cleaning up (Chandler|CHANDLER|CHAN) in 'Character' column\n",
    "#df_temp = df[df['Character'].str.contains('^Ch[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "df_temp = df[df['Character'].str.contains('^Ch', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "df['Character'] = df['Character'].replace('^\\s*(Chandler|CHANDLER|CHAN)\\s*$', 'Chandler', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "#cleaning up (Mike|MIKE|mike) in 'Character' column\n",
    "#df_temp = df[df['Character'].str.contains('^Mi[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "df_temp = df[df['Character'].str.contains('^Mi', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "df['Character'] = df['Character'].replace('^\\s*(Mike|MIKE|mike)\\s*$', 'Mike', regex=True)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#cleaning up (RACHEL|RACH|RAHCEL|Racel|Rache|Rache) in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Ra[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "\n",
    "#cleaning up (ROSS|ross|Ross) in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Ro[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "\n",
    "#cleaning up (Joey|JOEY|joey) in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Jo[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "\n",
    "#cleaning up (Monica|MONICA|monica) in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Mo[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "\n",
    "\n",
    "#cleaning up (Phoebe|PHOEBE|Phoehe|PHOE in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Ph[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "\n",
    "\n",
    "#cleaning up (Phoebe|PHOEBE|Phoehe|PHOE in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Ch[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "#cleaning up (Phoebe|PHOEBE|Phoehe|PHOE in 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Mi[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['Character'] = df['Character'].replace('^\\s*(RACHEL|RACH|RAHCEL|Racel|Rache|Rache)\\s*$', 'Rachel', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(ROSS|ross|Ross)\\s*$', 'Ross', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Joey|JOEY|joey)\\s*$', 'Joey', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Monica|MONICA|monica|MNCA)\\s*$', 'Monica', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Phoebe|PHOEBE|Phoehe|PHOE)\\s*$', 'Phoebe', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Chandlers?|CHANDLER|CHAN)\\s*$', 'Chandler', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Mike|MIKE|mike)\\s*$', 'Mike', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Janice|JANICE|janice|Janice\\’s Voice)\\s*$', 'Janice', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Charlie|CHARLIE)\\s*$', 'Charlie', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Carol|CAROL)\\s*$', 'Carol', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Emily|EMILY)\\s*$', 'Emily', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Mr(,|\\.)?\\s*Geller|Mr(,|\\.)?\\s*GELLER|MR(,|\\.)?\\s*GELLER)\\s*$', 'Mr. Geller', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Tag|TAG)\\s*$', 'Tag', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Paul|PAUL)\\s*$', 'Paul', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Frank|FRANK|Frank\\s+Jr\\.?|FRANK\\s+Jr\\.?)\\s*$', 'Frank Jr.', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Richard|RICHARD)\\s*$', 'Richard', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Gunther|GUNTHER|GUNTER)\\s*$', 'Gunther', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Amy|AMY)\\s*$', 'Amy', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Mrs(,|\\.)?\\s*Geller|Mrs(,|\\.)?\\s*GELLER|MRS(,|\\.)?\\s*GELLER)\\s*$', 'Mrs. Geller', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Mona|MONA)\\s*$', 'Mona', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Woman|WOMAN)\\s*$', 'Woman', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Pete|PETE)\\s*$', 'Pete', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(David|DAVID)\\s*$', 'David', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Joshua|JOSHUA)\\s*$', 'Joshua', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Gary|GARY)\\s*$', 'Gary', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Susan|SUSAN)\\s*$', 'Susan', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Elizabeth|ELIZABETH)\\s*$', 'Elizabeth', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Janine|JANINE)\\s*$', 'Janine', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Kathy|KATHY)\\s*$', 'Kathy', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Ben|BEN)\\s*$', 'Ben', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Jill|JILL)\\s*$', 'Jill', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Mr(,|\\.)\\s*Treeger|MR(,|\\.)\\s*TREEGER)\\s*$', 'Treeger', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Ursula|URSULA)\\s*$', 'Ursula', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Eric|ERIC)\\s*$', 'Eric', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Erica|ERICA)\\s*$', 'Erica', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Eddie|EDDIE)\\s*$', 'Eddie', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Gavin|GAVIN)\\s*$', 'Gavin', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Mr\\.\\s*Green|MR\\.\\s*GREEN)\\s*$', 'Green', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Kate|KATE)\\s*$', 'Kate', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Danny|DANNY)\\s*$', 'Danny', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Director|Director)\\s*$', 'Director', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Man|MAN)\\s*$', 'Man', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Guy|GUY)\\s*$', 'Guy', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Nurse|NURSE)\\s*$', 'Nurse', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Joanna|JOANNA)\\s*$', 'Joanna', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Mark|MARK)\\s*$', 'Mark', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Steve|STEVE)\\s*$', 'Steve', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Will|WILL)\\s*$', 'Will', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Doug|DOUG)\\s*$', 'Doug', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(M?r(,|\\.)?\\s*Zelner|M?r(,|\\.)?\\s*Zelner|M?R(,|\\.)?\\s*Zelner)\\s*$', 'Mr. Zelner', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Mindy|MINDY)\\s*$', 'Mindy', regex=True)\n",
    "df['Character'] = df['Character'].replace('^\\s*(Rachel\\s+and\\s+Monica|RACHEL\\s+AND\\s+MONICA|RACHEL\\s+and\\s+MONICA)\\s*$', 'Rachel and Monica', regex=True)\n",
    "\n",
    "\n",
    "#df['Location'] = df['Location'].replace(\"^\\s*(monica and rachel\\'s|monica and chandler\\'s|monica|monica and rachel\\'s apartment|monica and chandler\\'s apartment|monica\\'s apartment|monica and rachel\\'s erm|chandler and monica\\'s apartment|at monica and rachel\\'s|monica and rachel\\'s balcony|monica and phoebe\\'s|chandler and monica\\'s|rachel and monica\\'s|? monica and chandler\\'s apartment|rachel and monica\\'s apartment|monica and rachels apartment|change back an forth: monica and chandler\\'s apartment|monica and chandler\\'s aparment|chandler and monica\\'s apartement|monica and chandler\\'s apartment \\\" continuing action|chandler arrives home and monica\\'s got a video of sharks ready for chandler|monica and chandlers apartment|monica\\'s apartment continued|monica and rachel|monica\\'s living room|monica and rachel\\'s: everyone is there and they are watching an info-mercial that stars joey|a kitchen where phoebe and monica are finishing up a catering job|monica and chandler\\'s kitchen|in a tv commercial that the gang is watching at monica and rachel\\'s|monica and chandler\\'s apartement)\\s*$\", \"Monica\\'s Apartment\", regex=True)\n",
    "#df['Location'] = df['Location'].replace(\"^\\s*(monica and rachel\\'s|monica and chandler\\'s|monica|monica and rachel\\'s apartment|monica and chandler\\'s apartment|monica\\'s apartment|monica and rachel\\'s erm|chandler and monica\\'s apartment|at monica and rachel\\'s|monica and rachel\\'s balcony|monica and phoebe\\'s|chandler and monica\\'s|rachel and monica\\'s|? monica and chandler\\'s apartment|rachel and monica\\'s apartment|monica and rachels apartment|change back an forth: monica and chandler\\'s apartment|monica and chandler\\'s aparment|chandler and monica\\'s apartement)\\s*$\", \"Monica\\'s Apartment\", regex=True)\n",
    "#df['Location'] = df['Location'].replace(\"^\\s*(monica and rachel\\'s|monica and chandler\\'s)\\s*$\", \"Monica\\'s Apartment\", regex=True)\n",
    "#df['Location'] = df['Location'].replace(\"^\\s*(monica and rachel\\'s|monica and chandler\\'s|monica|monica and rachel\\'s apartment|monica and chandler\\'s apartment|monica\\'s apartment|monica and rachel\\'s erm|chandler and monica\\'s apartment)\\s*$\", \"Monica\\'s Apartment\", regex=True)\n",
    "\n",
    "df['Location'] = df['Location'].replace(\"^\\s*(chandler\\’s and monica\\’s apartment|chandler and monica\\’s|monica and chandler\\’s apartment|monica and rachel\\’s|monica and chandler\\’s|monica\\’s apartment|monica and rachel\\'s|monica and chandler\\'s|monica|monica and rachel\\'s apartment|monica and chandler\\'s apartment|monica\\'s apartment|monica and rachel\\'s erm|chandler and monica\\'s apartment|at monica and rachel\\'s|monica and rachel\\'s balcony|monica and phoebe\\'s|chandler and monica\\'s|rachel and monica\\'s|\\? monica and chandler\\'s apartment|rachel and monica\\'s apartment|monica and rachels apartment|change back an forth: monica and chandler\\'s apartment|monica and chandler\\'s aparment|chandler and monica\\'s apartement|monica and chandler\\'s apartment \\\" continuing action|chandler arrives home and monica\\'s got a video of sharks ready for chandler|monica and chandlers apartment|monica\\'s apartment continued|monica and rachel|monica\\'s living room|monica and rachel\\'s: everyone is there and they are watching an info-mercial that stars joey|a kitchen where phoebe and monica are finishing up a catering job|monica and chandler\\'s kitchen|in a tv commercial that the gang is watching at monica and rachel\\'s|monica and chandler\\'s apartement|mon and chan\\'s)\\s*$\", \"Monica\\'s Apartment\", regex=True)\n",
    "df['Location'] = df['Location'].replace(\"^\\s*(chandler walks into joey\\'s apartment|joey and janine\\’s apartment|joey\\'s|rachel and joey\\’s|joey and now rachel\\'s apartment|chandler and joey\\’s|joey\\’s|joey(\\'|\\’)s apartment|chandler joey and ross\\'s|chandler joey and ross\\'s apartment|joey and janine\\’s|joey and rachel\\'s|joey and rachel\\'s apartment|chandler and joey\\\\'s|chandler and joey\\\\'s apartment|at chandler and joey\\\\'s|chandler\\\\'s office|chandler and joey\\\\'s erm|chandler and eddie\\\\'s apartment|chandler\\\\'s apartment|chandler and joey\\\\'s and ross\\\\'s|chandler and joey\\\\'s chandler is talking with his mom|back in chandler and joey\\\\'s apartment)\\s*$\", \"Chandler and Joey\\'s Apartment\", regex=True)                                        \n",
    "df['Location'] = df['Location'].replace(\"^\\s*(ross and rachel\\'s apartment|ross and rachel\\’s|ross and rachel's)\\s*$\", \"Ross and Rachel's Apartment\", regex=True)                                        \n",
    "df['Location'] = df['Location'].replace(\"^\\s*(ross\\'s apartment|ross\\' apartment|ross\\'|ross|ross\\?|ross\\'s room|ross\\'s apartment the next morning|ross\\'s place|ross\\'s apartment)\\s*$\", \"Ross's Apartment\", regex=True)                                        \n",
    "df['Location'] = df['Location'].replace(\"^\\s*(phoebe\\'s apartment|phoebe\\’s)\\s*$\", \"Phoebe's Apartment\", regex=True)                                        \n",
    "df['Location'] = df['Location'].replace(\"^\\s*(ross is in central perk|phoebe is in central|monica enters central perk|centr?al perk|inside central perk|central perk\\’s)\\s*$\", \"Central Perk\", regex=True)                                        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the unique characters and their corresponding dialogue count\n",
    "print (df['Character'].value_counts().head(20) )\n",
    "print (df['Location'].value_counts().head(20) )\n",
    "\n",
    "\"\"\"\n",
    "#cleaning up 'Character' column\n",
    "df_temp = df[df['Character'].str.contains('^Em', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "df['Character'] = df['Character'].replace('^\\s*(Emily|EMILY)\\s*$', 'Emily', regex=True)\n",
    "\n",
    "df_temp = df[df['Character'].str.contains('^Em[^ /]+\\s*$', flags=re.IGNORECASE, regex=True)]\n",
    "print (df_temp['Character'].value_counts())\n",
    "\"\"\"\n",
    "\n",
    "#print (df)\n",
    "df.to_csv('../dataset/friends_dataset_allseasons.csv',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial findings are below, need to work on Analysis \n",
    "\n",
    "Total number of Lines of Lead Characters:\n",
    "\n",
    "Rachel        9294\n",
    "Ross          9175\n",
    "Chandler      8454\n",
    "Monica        8437\n",
    "Joey          8198\n",
    "Phoebe        7531\n",
    "\n",
    "Total number of Lines of Top 5 supporting character:\n",
    "\n",
    "Mike            360\n",
    "Richard         254\n",
    "Mr. Geller      231\n",
    "Janice          219\n",
    "Carol           205\n",
    "\n",
    "Top 5 sets:\n",
    "\n",
    "Monica's Apartment               18561\n",
    "Central Perk                     10896\n",
    "Chandler and Joey's Apartment     7188\n",
    "Ross's Apartment                  1228\n",
    "the hallway                        692\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
